
\section{Conclusion}
\label{sec:conclusion}

\begin{comment}
\begin{description}
    \begin{itemize}
        
        \item Training & Testing mit adversarial Ansatz besser als bisher dagewesene Methoden zur Generation von trainingsset & testing
        \item kann zu superhuman fähigkeiten führen (evtl + gans)
        \item Aufgreifen von Beispiel autonom. Fahren --> was bringt adv. hier?
        \item --> moral machine (viele fragen bleiben offen, adv training kann helfen, robuster zu machen und einen schritt in richtung reale welt)
        
    \end{itemize}

  
\end{description}




Adv. Training:
\begin{description}

    \begin{itemize}
        \item training enables the generation of training sets that prepare and train agents for risks and complex circumstances
        \item self-play: Pure reinforcement learning approach (without supervision) is fully feasible \cite{GoalphaGosilver2017mastering}. Even in most challenging domains given only basic rules. (siehe alphaGo zero)
        \item Future work: interesting to see how larger experiments perform in more complex environments, More studies on how Agents compete and cooperate with each other (siehe dota2 5 neuronale netze cooperative & competing)
        \item GANs promise amazing generation of datasets (which can be used in gaming, fashion etc.)
    \end{itemize}
\end{description}

Co-Evolutional Testing -> gemeinsame Aussichten und Probleme beider Methoden
\begin{description}

    \begin{itemize}
        \item Erklärung, dass Training und Testing oft ineinander verschwimmt.
        \item Rückschluss auf Probleme der jeweiligen Methoden -> weitere mögliche Forschung
    \end{itemize}


\end{description}
\end{comment}
For both AI and humans, when used in the real world, critical, unpredictable circumstances can arise through complex environments for which the agent is not prepared. In the example of autonomous driving, those scenarios can mean the loss of human life. In order to reduce this risk and to make the agent as robust as possible, there are approaches to adversarial/co-evolutionary training and testing which have been dealt with in this thesis. These approaches enable the generation of a complex training and testing set, confronting the agent with risks and complex circumstances.\\
We have looked at different adversarial training approaches that provide amazing results in certain applications (chapter \ref{adv_training}). For example, RARL (section \ref{appl_train}) enabled agents to be robust against changes in the environment. Self-play (section \ref{selfplay}) led to superhuman performance in several games (Backgammon, Chess, Go, Dota2) using pure reinforcement learning approach (without supervision) and GANs enable the generation of e.g. deceptively real faces that do not exist in the real world.\\
Furthermore, competitive co-evolutionary inspired algorithms can be used for evaluating agents. Despite fundamentally different approaches, both AVF (section \ref{avf}) and SCoE (section \ref{coevolution}) demonstrably outperform traditional random testing methods by identifying rare, fatal failures of the trained agent. Additionally, testing is less time consuming with these algorithms. With these concepts, we have described state of the art evaluation methods for both, multi-agent and continuous domains.\\
In summary, co-evolutionary and adversarial machine learning provide new possibilities to prepare AI for the real world and integrate it as safely as possible into our everyday lives. But of course, this step is only one of many that will follow and occupy scientists in the coming years. And even when agents reliably make the "seemingly" right decisions, there are other features that a machine must satisfy in order to exist in harmony with society. The Moral Machine Experiment of MIT, for example, deals with the question how AI can make moral decisions and according to which ethical guidelines or social ideas these should be evaluated \cite{awad2018moral}.